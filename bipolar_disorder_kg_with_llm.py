# -*- coding: utf-8 -*-
"""Copy of Bipolar_disorder_KG_with_LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cIsvu22X832EAAtxqnP_4T2Xqf3NDlhk
"""

your_openai_api_key = "YOUR_API_KEY"

# Install the necessary packages
!pip install -q openai langchain langchain-openai langchain-community faiss-cpu langchainhub

"""# Import dependencies and create environment variables"""

# Import required libraries
import os
import openai
import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains import GraphCypherQAChain, GraphQAChain
from langchain.indexes import GraphIndexCreator
from langchain.graphs.networkx_graph import KnowledgeTriple
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain import hub
from langchain.schema import StrOutputParser
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from uuid import uuid4

# Set up OpenAI API key
os.environ['OPENAI_API_KEY'] = your_openai_api_key
openai.api_key = os.environ['OPENAI_API_KEY']

# Initialize OpenAI Chat model
llm = ChatOpenAI()

# load data from csv
CMG_path = '/content/Converted_Neo4j_Bipolar_Knowledge_Graph.csv'
df = pd.read_csv(CMG_path)

# load test data from csv
test_path = '/content/QA_data.csv'
test_df = pd.read_csv(test_path, encoding='cp1252')

"""# validating that data is loaded"""

test_df.head()

df.head()

"""# Import CMG data to create knowledge graph"""

index_creator = GraphIndexCreator(llm=llm)
text = ""
graph = index_creator.from_text(text)
for index, row in df.iterrows():
    # Extract information from the row
    main_head = row['Main Head']
    main_relation = row['Main Relation']
    main_tail = row['Main Tail']
    sub_head = row['Sub Head']
    sub_relation = row['Sub Relation']
    sub_tail = row['Sub Tail']
    relation_to_main = row['Relation to Main']

    # Add the main triple
   # graph = index_creator.from_text(f"{main_head} {main_relation} {main_tail}")
    graph.add_triple(KnowledgeTriple(main_head, main_relation, main_tail))


    # Add the sub triples
    if pd.notna(sub_head) and pd.notna(sub_relation) and pd.notna(sub_tail):
        graph.add_triple(KnowledgeTriple(sub_head, sub_relation, sub_tail))

    # Optionally, you can also add relations to main as separate triples if needed
    if pd.notna(relation_to_main):
        graph.add_triple(KnowledgeTriple(sub_head, relation_to_main, main_head))

print("Data successfully added to the knowledge graph.")

import networkx as nx
import pandas as pd
import matplotlib.pyplot as plt

# Create a directed graph
G = nx.DiGraph()

# Add only the first 20 rows to the graph
for index, row in df.head(20).iterrows():  # Use .head(10) to limit to the first 10 rows
    # Extract information from the row
    main_head = row['Main Head']
    main_relation = row['Main Relation']
    main_tail = row['Main Tail']
    sub_head = row['Sub Head']
    sub_relation = row['Sub Relation']
    sub_tail = row['Sub Tail']
    relation_to_main = row['Relation to Main']

    # Add the main triple
    G.add_edge(main_head, main_tail, label=main_relation)

    # Add the sub triples
    if pd.notna(sub_head) and pd.notna(sub_relation) and pd.notna(sub_tail):
        G.add_edge(sub_head, sub_tail, label=sub_relation)

    # Optionally, add relations to main as separate triples if needed
    if pd.notna(relation_to_main):
        G.add_edge(sub_head, main_head, label=relation_to_main)

# Plot the graph
plt.figure(figsize=(25, 15), dpi=300)
pos = nx.spring_layout(G, k=2, iterations=50, seed=0)  # Layout for positioning nodes

# Draw nodes
nx.draw_networkx_nodes(G, pos, node_size=500, node_color='lightblue')

# Draw edges
nx.draw_networkx_edges(G, pos, edge_color='gray', edgelist=G.edges(), width=2)

# Draw node labels
nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')

# Draw edge labels
edge_labels = nx.get_edge_attributes(G, 'label')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)

# Display the plot
plt.axis('off')  # Turn off the axis
plt.show()

# Create a directed graph for visualization
G = nx.DiGraph()

# Add triples to the graph
for index, row in df.iterrows():
    # Extract information from the row
    main_head = row['Main Head']
    main_relation = row['Main Relation']
    main_tail = row['Main Tail']
    sub_head = row['Sub Head']
    sub_relation = row['Sub Relation']
    sub_tail = row['Sub Tail']
    relation_to_main = row['Relation to Main']

    # Add the main triple
    G.add_edge(main_head, main_tail, label=main_relation)

    # Add the sub triples
    if pd.notna(sub_head) and pd.notna(sub_relation) and pd.notna(sub_tail):
        G.add_edge(sub_head, sub_tail, label=sub_relation)

    # Optionally, add relations to main as separate triples if needed
    if pd.notna(relation_to_main):
        G.add_edge(sub_head, main_head, label=relation_to_main)

# Plot the graph
plt.figure(figsize=(25, 15), dpi=300)
pos = nx.spring_layout(G, k=2, iterations=50, seed=0)  # Layout for positioning nodes

# Draw nodes
nx.draw_networkx_nodes(G, pos, node_size=500, node_color='lightblue')

# Draw edges
nx.draw_networkx_edges(G, pos, edge_color='gray', edgelist=G.edges(), width=2)

# Draw node labels
nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')

# Draw edge labels
edge_labels = nx.get_edge_attributes(G, 'label')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=6)

# Display the plot
plt.axis('off')  # Turn off the axis
plt.show()

print(f"Number of nodes: {G.number_of_nodes()}")
print(f"Number of edges: {G.number_of_edges()}")

question2= "Who has higher chance of having bipolar disorder?"
question3= "What is the cause of bipolar disorder?"

# load test data from csv
test_path = '/content/QA_data.csv'
test_df = pd.read_csv(test_path, encoding='cp1252')

"""## Compare Question answering without CMG graph, and with CMG graph"""

completion = openai.chat.completions.create(model="gpt-3.5-turbo-0125",
  temperature=0,
  messages=[{"role": "user",
  "content": question3}])
print(completion.choices[0].message.content)

chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)
chain.invoke(question3)

"""End demo

### Evaluation
"""

# Question-answering WITHOUT CMG graph
# def answer_without_cmg(question):
#     completion = openai.chat.completions.create(
#         model="gpt-3.5-turbo-0125",
#         temperature=0,
#         messages=[{"role": "user", "content": question}]
#     )
#     return completion.choices[0].message.content

# Question-answering WITH CMG graph
def answer_with_cmg(clinical_note, graph, llm):
    question = f"Based on the clinical note: '{clinical_note}', is the diagnosis related to bipolar Disorder (BP)?"
    chain = GraphQAChain.from_llm(llm, graph=graph, verbose=True)
    result = chain.invoke(question)
    return result.get('result')

def answer_question(clinical_note):
    question = f"Based on the clinical note: '{clinical_note}', is the diagnosis related to Bipolar Disorder (BP)?"

    completion = openai.chat.completions.create(
        model="gpt-3.5-turbo-0125",
        temperature=0,
        messages=[{"role": "user", "content": question}]
    )

    # Extract response
    return completion.choices[0].message.content

from sklearn.metrics import precision_score, recall_score, f1_score
# Function to map OpenAI answers to binary classification (BP-related or Not)
def map_prediction_to_diagnosis(predicted_answer):
    if "Bipolar" in predicted_answer or "BP" in predicted_answer or "memory" in predicted_answer:
        return "Bipolar-related"
    else:
        return "Not Bipolar-related"
# Process dataset and get predictions
test_df['Predicted Diagnosis'] = test_df['Clinical Note'].apply(answer_question)

# Map the predictions
test_df['Mapped Diagnosis'] = test_df['Predicted Diagnosis'].apply(map_prediction_to_diagnosis)

# Calculate accuracy
accuracy = (test_df['Diagnosis'] == test_df['Mapped Diagnosis']).mean()
print(f"Accuracy: {accuracy * 100:.2f}%")

# Calculate precision, recall, and F1 score
precision = precision_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')
recall = recall_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')
f1 = f1_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')

print(f"Precision: {precision * 100:.2f}%")
print(f"Recall: {recall * 100:.2f}%")
print(f"F1 Score: {f1 * 100:.2f}%")

# Print the final dataframe
print(test_df[['Clinical Note', 'Diagnosis', 'Predicted Diagnosis', 'Mapped Diagnosis']])

# Export to CSV
test_df.to_csv('test_df_wo_graph.csv', index=False)

# Function to map OpenAI answers to binary classification (BP-related or Not)
def map_prediction_to_diagnosis(predicted_answer):
    if "Yes" in predicted_answer:
        return "Bipolar-related"
    elif "No" in predicted_answer:
        return "Not Bipolar-related"
    else:
        # Default or ambiguous cases can be handled if needed
        return "Not Bipolar-related"
# Process dataset and get prediction using Graph
test_df['Predicted Diagnosis'] = test_df['Clinical Note'].apply(answer_with_cmg, graph=graph, llm=llm)

# Map the predictions
test_df['Mapped Diagnosis'] = test_df['Predicted Diagnosis'].apply(map_prediction_to_diagnosis)

# Calculate accuracy
accuracy = (test_df['Diagnosis'] == test_df['Mapped Diagnosis']).mean()
print(f"Accuracy: {accuracy * 100:.2f}%")
# Calculate precision, recall, and F1 score
precision = precision_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')
recall = recall_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')
f1 = f1_score(test_df['Diagnosis'], test_df['Mapped Diagnosis'], average='weighted')

print(f"Precision: {precision * 100:.2f}%")
print(f"Recall: {recall * 100:.2f}%")
print(f"F1 Score: {f1 * 100:.2f}%")
# Print the final df
print(test_df[['Clinical Note', 'Diagnosis', 'Predicted Diagnosis', 'Mapped Diagnosis']])
# export to csv
test_df.to_csv('test_df_w_graph.csv', index=False)